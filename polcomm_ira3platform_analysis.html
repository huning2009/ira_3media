<pre><code class="r setup, include=FALSE">library(dplyr)
library(tidyr)
library(ggplot2)

library(fracdiff)
library(forecast) #core ts package
library(tseries) #core ts package
library(vars) #for running VARs
library(prais)
library(lmtest)
library(xts) #date-time organizer
</code></pre>

<p>#Data Import</p>

<p>In this section, I import the time series data and aggregate to the weekly level</p>

<pre><code class="r import-data">pol_cont2 &lt;- read.csv(&quot;polcomm_ira3platform_data.csv&quot;, header = TRUE, sep = &quot;,&quot;) 
colnames(pol_cont2) #used to see column names
pol_cont2$date &lt;- as.Date(pol_cont2$date, format = &quot;%m/%d/%Y&quot;)

xts_sock_tw &lt;- ts(pol_cont2$sock_tw) %&gt;% xts (order.by = pol_cont2$date) %&gt;% apply.weekly(sum) 
xts_sock_fb &lt;- ts(pol_cont2$sock_fb) %&gt;% xts (order.by = pol_cont2$date) %&gt;% apply.weekly(sum)
xts_sock_reddit &lt;- ts(pol_cont2$sock_reddit) %&gt;% xts (order.by = pol_cont2$date) %&gt;% apply.weekly(sum)
xts_sock_ru2us &lt;- ts(pol_cont2$ru2us) %&gt;% xts (order.by = pol_cont2$date) %&gt;% apply.weekly(sum) #all RU to US events
xts_sock_us2ru &lt;- ts(pol_cont2$us2ru) %&gt;% xts (order.by = pol_cont2$date) %&gt;% apply.weekly(sum) #all US to RU events
xts_trump_approve &lt;- ts(pol_cont2$trump_favorable) %&gt;% xts (order.by = pol_cont2$date) %&gt;% apply.weekly(mean)
xts_us_event &lt;- ts(pol_cont2$us_pol_event) %&gt;% xts (order.by = pol_cont2$date) %&gt;% apply.weekly(sum)


xts_ru2us_disagree &lt;- ts(pol_cont2$ru2us_disagree) %&gt;% xts (order.by = pol_cont2$date) %&gt;% apply.weekly(sum) #CAMEO 11 and 12
xts_ru2us_threat &lt;- ts(pol_cont2$ru2us_threat) %&gt;% xts (order.by = pol_cont2$date) %&gt;% apply.weekly(sum) #CAMEO 13 and 15
xts_us2ru_threat &lt;- ts(pol_cont2$us2ru_threat) %&gt;% xts (order.by = pol_cont2$date) %&gt;% apply.weekly(sum) #CAMEO 13 and 15
xts_us2ru_disagree &lt;- ts(pol_cont2$us2ru_disagree) %&gt;% xts (order.by = pol_cont2$date) %&gt;% apply.weekly(sum) #CAMEO 11 and 12

</code></pre>

<p>#Data Descriptives
IRA Tweets and Retweets: <a href="https://blog.twitter.com/en_us/topics/company/2018/enabling-further-research-of-information-operations-on-twitter.html">https://blog.twitter.com/en_us/topics/company/2018/enabling-further-research-of-information-operations-on-twitter.html</a><br/>
IRA Facebook Ads: <a href="https://intelligence.house.gov/social-media-content/social-media-advertisements.htm">https://intelligence.house.gov/social-media-content/social-media-advertisements.htm</a><br/>
IRA Reddit Accounts: <a href="https://www.reddit.com/wiki/suspiciousaccounts">https://www.reddit.com/wiki/suspiciousaccounts</a>  </p>

<p>Approval of Trump: <a href="https://www.realclearpolitics.com/epolls/other/trump_favorableunfavorable-5493.html#polls">https://www.realclearpolitics.com/epolls/other/trump_favorableunfavorable-5493.html#polls</a><br/>
Event count are from GDELT: <a href="https://www.gdeltproject.org/data.html">https://www.gdeltproject.org/data.html</a> 
  Events were identified using the CAMEO codes: <a href="http://data.gdeltproject.org/documentation/CAMEO.Manual.1.1b3.pdf">http://data.gdeltproject.org/documentation/CAMEO.Manual.1.1b3.pdf</a><br/>
  For events, &ldquo;disagree&rdquo; refers to the following categories: Demand (10), Disapprove (11), and Reject (12)<br/>
  For events, &ldquo;threat&rdquo; refers to the followig categories: Threat (13) and Military Posturing (15)  </p>

<p>I plot the 8 time series below: the 3 time series of IRA activity, the 4 time series of Russia to US and US to Russian activity, and Trump&#39;s approval rating.</p>

<pre><code class="r plottage">ggtsdisplay(xts_sock_reddit, plot.type = &quot;partial&quot;, points = FALSE, smooth = TRUE, 
            main = &quot;Count of IRA Posts and Comments on Reddit&quot;,
            xlab = &quot;Weekly&quot;,
            ylab = &quot;Number of Posts&quot;)  #not stationary

ggtsdisplay(xts_sock_fb, plot.type = &quot;partial&quot;, points = FALSE, smooth = TRUE, 
            main = &quot;Count of IRA Facebook Ads&quot;,
            xlab = &quot;Weekly&quot;,
            ylab = &quot;Number of Ads&quot;)  #not stationary

ggtsdisplay(xts_sock_tw, plot.type = &quot;partial&quot;, points = FALSE, smooth = TRUE, 
            main = &quot;Count of IRA tweets and retweets&quot;,
            xlab = &quot;Weekly&quot;,
            ylab = &quot;Number of Tweets&quot;)  #not stationary


ggtsdisplay(xts_ru2us_threat, plot.type = &quot;partial&quot;, points = FALSE, smooth = TRUE, 
            main = &quot;Count of Russian force signaling towards US&quot;,
            xlab = &quot;Weekly&quot;,
            ylab = &quot;Number of Events&quot;)  #not stationary

ggtsdisplay(xts_ru2us_disagree, plot.type = &quot;partial&quot;, points = FALSE, smooth = TRUE,
            main = &quot;Count of Russia disagreeing with the US&quot;,
            xlab = &quot;Weekly&quot;,
            ylab = &quot;Number of Events&quot;)  #not stationary

ggtsdisplay(xts_us2ru_threat, plot.type = &quot;partial&quot;, points = FALSE, smooth = TRUE, 
            main = &quot;Count of US force signaling towards Russia&quot;,
            xlab = &quot;Weekly&quot;,
            ylab = &quot;Number of Events&quot;)  #not stationary

ggtsdisplay(xts_us2ru_disagree, plot.type = &quot;partial&quot;, points = FALSE, smooth = TRUE,
            main = &quot;Count of US disagreeing with Russia&quot;,
            xlab = &quot;Weekly&quot;,
            ylab = &quot;Number of Events&quot;)  #not stationary

ggtsdisplay(xts_trump_approve, plot.type = &quot;partial&quot;, points = FALSE, smooth = TRUE, #median follower of acct
            main = &quot;Approval Rating of Trump (Candidate/President)&quot;,
            xlab = &quot;Weekly&quot;,
            ylab = &quot;Approval Rating&quot;)  #not stationary

</code></pre>

<pre><code class="r ggplotter, echo=FALSE, include = FALSE">plotter &lt;- data.frame(reddit = xts_sock_reddit, date = as.POSIXct(time(xts_sock_reddit)))

ggplot(plotter, aes(x = date)) + geom_line(aes(y = reddit)) + 
  scale_x_datetime(breaks = &quot;10 weeks&quot;) +
  theme(axis.text=element_text(size=8,face=&quot;bold&quot;, angle = -45)) #1300 x 350
</code></pre>

<p>Plot of IRA activity on Facebook, Twitter, and Reddit</p>

<pre><code class="r plot">ts.plot(ts(xts_sock_fb), ts(xts_sock_tw), ts(xts_sock_reddit), gpars = list(col = c(&quot;blue&quot;,&quot;light blue&quot;,&quot;red&quot;)),
        main = &quot;IRA on Facebook ads (blue), Twitter (light blue) and Reddit (red)&quot;,
        xlab = &quot;Daily&quot;, ylab = &quot;# of Posts&quot;) +
  abline(v=550, col=&quot;dark grey&quot;, lty = 2)
</code></pre>

<p>##Univariate Analysis</p>

<pre><code class="r univaranalysis">#auto.arima(xts_sock_reddit, ic = &quot;bic&quot;, trace = TRUE)
reddit_arima &lt;- auto.arima(xts_sock_reddit, ic=&quot;bic&quot;)
#plot(reddit_arima)
#plot(forecast(reddit_arima, h = 10))

fb_arima &lt;- auto.arima(xts_sock_fb, ic = &quot;bic&quot;)
tw_arima &lt;- auto.arima(xts_sock_tw, ic = &quot;bic&quot;)#arfima(xts_sock_tw, ic=&quot;bic&quot;)

reddit_arima
fb_arima
tw_arima
</code></pre>

<p>##Correlation Check</p>

<pre><code class="r corrs">reddit_resid &lt;- reddit_arima$residuals
fb_resid &lt;- fb_arima$residuals
tw_resid &lt;- tw_arima$residuals

#resid &lt;- data.frame(reddit = reddit_resid, fb = fb_resid, tw= tw_resid)

cor.test(reddit_resid, fb_resid)
cor.test(fb_resid, tw_resid)
cor.test(reddit_resid, tw_resid)

</code></pre>

<h1>VAR Analysis</h1>

<p>In this section, I prepare the data for a VAR analysis by first-differencing non-stationary series, and by organizing the variables into the appropriate order.</p>

<p>##Fractional Integration &amp; Diff
To do a VAR analysis, it is necessary to remove the integrated component of the above time series. Most of the time series are fully-integrated, one is fractionaly-so. These will be differenced out.</p>

<pre><code class="r fracdiff">ndiffs(xts_sock_fb)
ndiffs(xts_sock_tw)
ndiffs(xts_sock_reddit) 

ndiffs(xts_trump_approve) 
ndiffs(xts_us_event) #stationary

ndiffs(xts_ru2us_disagree)
ndiffs(xts_ru2us_threat) 
ndiffs(xts_us2ru_disagree) 
ndiffs(xts_us2ru_threat) 

fd_sock_fb &lt;- diff(xts_sock_fb, d = 1)
fd_sock_tw &lt;- diff(xts_sock_tw, differences = 1)
fd_sock_reddit &lt;- diff(xts_sock_reddit, differences = 1)

fd_ru2us_disagree &lt;- diff(xts_ru2us_disagree, differences = 1)
fd_ru2us_threat &lt;- diff(xts_ru2us_threat, differences = 1)

fd_us2ru_threat &lt;- diff(xts_us2ru_threat, differences = 1)
fd_us2ru_disagree &lt;- diff(xts_us2ru_disagree, differences = 1)

fd_trump_approval &lt;- diff(xts_trump_approve, differences = 1)

ts.plot(ts(fd_sock_fb), ts(fd_sock_reddit), ts(fd_sock_tw), gpars = list(col = c(&quot;blue&quot;,&quot;red&quot;,&quot;light blue&quot;)),
        main = &quot;IRA on Facebook ads (blue), Twitter (light blue) and Reddit (red)&quot;,
        xlab = &quot;Daily&quot;, ylab = &quot;# of Posts&quot;)
</code></pre>

<p>All series had unit roots and were first-differenced.</p>

<h2>Cointegration Test</h2>

<p>This checked for co-integration betwen my sockpuppet activity time series. For my edification, I also checked the sockpuppet activity on Twitter and Trump approval. There appears to be no co-integrated relationships.</p>

<pre><code class="r cointegrate">library(egcm)
cointegration_fbtw &lt;- data.frame(xts_sock_fb, xts_sock_tw) %&gt;% ts()
cointegrate_fbtw &lt;- egcm(cointegration_fbtw)
#plot(cointegrate_fbtw)

cointegration_fbrd &lt;- data.frame(xts_sock_fb, xts_sock_reddit) %&gt;% ts()
cointegrate_fbrd &lt;- egcm(cointegration_fbrd)
#plot(cointegrate_fbtw)

cointegration_rdtw &lt;- data.frame(xts_sock_reddit, xts_sock_tw) %&gt;% ts()
cointegrate_rdtw &lt;- egcm(cointegration_fbtw)
#plot(cointegrate_fbtw)

is.cointegrated(cointegrate_fbtw)
is.cointegrated(cointegrate_fbrd)
is.cointegrated(cointegrate_rdtw)
</code></pre>

<pre><code class="r coint_trumptw">ts.plot(ts(xts_sock_tw), ts(xts_trump_approve), gpars = list(col = c(&quot;blue&quot;,&quot;black&quot;)),
        main = &quot;IRA on Twitter (Blue) and Trump Approval (Black)&quot;,
        xlab = &quot;Daily&quot;, ylab = &quot;-&quot;)

cointegration_tw_trump &lt;- data.frame(xts_sock_tw, xts_trump_approve) %&gt;% ts()
cointegrate_tw_trump &lt;- egcm(cointegration_tw_trump)
is.cointegrated(cointegrate_tw_trump)
</code></pre>

<h1>Vector AutoRegression</h1>

<pre><code class="r var-order">#First Differenced
sockpuppet_var &lt;- data.frame(sock_fb = fd_sock_fb, sock_tw = fd_sock_tw, sock_reddit = fd_sock_reddit,
                             ru2us_disagree = fd_ru2us_disagree,
                             ru2us_threat = fd_ru2us_threat,
                             #us_event = xts_us_event
                             us2ru_disagree = fd_us2ru_disagree,
                             us2ru_threat = fd_us2ru_threat,
                             trump_approval = fd_trump_approval
                             ) #follower count
#colnames(sockpuppet_var)
var_endo &lt;- subset(sockpuppet_var, select = c(sock_fb, sock_reddit, sock_tw))

var_exo &lt;- subset(sockpuppet_var, select = c(ru2us_disagree, ru2us_threat, us2ru_disagree, us2ru_threat, trump_approval))
</code></pre>

<p>Now, we want to select the appropriate number of lags.</p>

<pre><code class="r lagselection">library(tsDyn)

tot &lt;- lags.select(var_endo, lag.max = 8) #I like this one because I rely on the BIC most often
tot
tot$BICs
tot$AICs
</code></pre>

<p>BIC (Baysian Info Criterion) recommends a lag of 2.</p>

<p>Toda Yamamoto Method for Two-Way Granger Causality, holding all else constant.</p>

<pre><code class="r gc-function">toda.yamamoto &lt;- function(var) {
  # add the magic lag to the existing VAR model
  ty.df &lt;- eval(var$call$y);
  ty.varnames &lt;- colnames(ty.df);
  ty.lags &lt;- var$p + 2;
  ty.augmented_var &lt;- VAR(ty.df, ty.lags, type=var$type);

  ty.results &lt;- data.frame(predictor = character(0), causes = character(0), chisq = numeric(0), p = numeric(0));

  for (current_variable in ty.varnames) {
    # construct the restriction matrix: to test if *current_variable* causes any of the others,
    # we test if the lagged values of current variable (ignoring the magic lag) are jointly insignificant

    ty.restrictions &lt;- as.matrix(Bcoef(ty.augmented_var))*0+1;
    ty.coefres &lt;- head(grep(current_variable, colnames(ty.restrictions), value=T), -1);
    ty.restrictions[which(rownames(ty.restrictions) != current_variable), ty.coefres] &lt;- 0;
    # estimate restricted var
    ty.restricted_var &lt;- restrict(ty.augmented_var, &#39;manual&#39;, resmat=ty.restrictions);

    for (k in 1:length(ty.varnames)) {
      if (ty.varnames[k] != current_variable) {
        my.wald &lt;- waldtest(ty.augmented_var$varresult[[k]], ty.restricted_var$varresult[[k]], test=&#39;Chisq&#39;);
        ty.results &lt;- rbind(ty.results, data.frame(
                        predictor = current_variable, 
                        causes = ty.varnames[k], 
                        chisq = as.numeric(my.wald$Chisq[2]), 
                        p = my.wald$`Pr(&gt;Chisq)`[2])
        );
      }
    }
  }
  return(ty.results);
}
</code></pre>

<p>#VAR - Events as Exogenous</p>

<pre><code class="r var-exo">var_endo2 &lt;- var_endo[2:101,]
var_exo2 &lt;- var_exo[2:101,] %&gt;% as.data.frame()

varresult_x &lt;- VAR(var_endo2, p = 2, exogen = var_exo2) #run VAR analysis 
summary(varresult_x)
</code></pre>

<p>##Two-way Granger Causality</p>

<pre><code class="r toda-x">toda.yamamoto(varresult_x)
</code></pre>

<h2>Impact Response Functions</h2>

<pre><code class="r irfs-x">plot(irf(varresult_x, impulse = &quot;sock_reddit&quot;, response = &quot;sock_tw&quot;, n.ahead = 5, ortho = FALSE, cumulative = TRUE)) +
  title(sub = &quot;Shock = Reddit // Response = Twitter&quot;)
plot(irf(varresult_x, impulse = &quot;sock_tw&quot;, response = &quot;sock_reddit&quot;, n.ahead = 5, ortho = FALSE, cumulative = TRUE)) +
  title(sub = &quot;Shock = Twitter // Response = Reddit&quot;)
</code></pre>

<h1>Model Checking</h1>

<p>##Endogeneity Test of Residuals
Durbin-Watson Test</p>

<pre><code class="r endog-x">dwtest(varresult_x$varresult$sock_fb, exact = FALSE)
dwtest(varresult_x$varresult$sock_tw, exact = FALSE)
dwtest(varresult_x$varresult$sock_reddit, exact = FALSE)
</code></pre>

<p>##Residuals Check
Ljung-Box Test</p>

<pre><code class="r residuals-x">residualz &lt;- residuals(varresult_x)
colnames(residualz)
Box.test(residualz[,1], type=&#39;Ljung&#39;,lag=1) # retweets
Box.test(residualz[,2], type=&#39;Ljung&#39;,lag=1) # network followers
Box.test(residualz[,3], type=&#39;Ljung&#39;,lag=1) #interaction with verified actors

</code></pre>

<p>These results confirm that the data are radomly distributed. A plot of the residuals appears to look like white noise.</p>

<pre><code class="r plotter">ggtsdisplay(residualz[,1])
ggtsdisplay(residualz[,2])
ggtsdisplay(residualz[,3])
</code></pre>

